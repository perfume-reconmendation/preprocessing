{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./top_90_by_gender.csv')\n",
    "df.head()\n",
    "\n",
    "df = df[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   gender   20 non-null     object\n",
      " 1   name     20 non-null     object\n",
      " 2   accords  20 non-null     object\n",
      " 3   review   20 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 768.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Got a sample of this today, and my 9 year old ...\n1    First impressions. Test on blotter.\\r\\nI have ...\n2    This perfume reminds me of my best friend. Act...\n3    Imagine tripping over your own feet and fallin...\n4    Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....\n5    I tested the most recent formulation and alas....\n6    For the last six months I've been hearing good...\n7    Honestly for those who haven't smelt it before...\n8    I've recently discovered this perfume and have...\n9    I did vote for \"love\", but with love, I meant ...\nName: review, dtype: object"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = df['review']\n",
    "reviews[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Got a sample of this today, and my 9 year old ...\n1    First impressions. Test on blotter.\\r\\nI have ...\n2    This perfume reminds me of my best friend. Act...\n3    Imagine tripping over your own feet and fallin...\n4    Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....\n5    I tested the most recent formulation and alas....\n6    For the last six months I've been hearing good...\n7    Honestly for those who haven't smelt it before...\n8    I've recently discovered this perfume and have...\n9    I did vote for \"love\", but with love, I meant ...\nName: review, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, review in reviews.iteritems():\n",
    "    if type(review) != str:\n",
    "        reviews[idx] = ''\n",
    "\n",
    "reviews[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Got', 'a', 'sample', 'of', 'this', 'today', ',', 'and', 'my', '9', 'year', 'old', 'daughter', 'and', 'I', 'both', 'had', 'the', 'same', 'thought', 'on', 'smelling', 'it', 'when', 'sprayed', 'on', 'a', 'card', '-', 'rotten', 'fish.', 'I', 'very', 'nearly', 'threw', 'it', 'out', 'immediately.', 'However', ',', 'later', 'this', 'evening', 'I', 'decided', 'to', 'give', 'it', 'a', 'fair', 'trial', 'and', 'sprayed', 'it', 'into', 'the', 'crook', 'of', 'my', 'elbows.', 'No', 'rotting', 'fish', 'smell', 'this', 'time', ',', 'but', 'I', 'got', 'a', 'definite', 'bit', 'of', 'funk', ',', 'almost', 'a', 'urine', 'scent', '...', 'and', 'after', 'about', '10', 'minutes', 'it', 'just', 'blossomed', 'into', 'the', 'most', 'gorgeous', 'smooth', 'woody', ',', 'ambery', 'but', 'clean', ',', 'warm', 'jasmine.', 'My', 'daughter', 'didn’t', 'even', 'believe', 'me', 'when', 'I', 'told', 'her', 'it', 'was', 'the', 'same', 'fragrance', 'she', 'smelled', 'earlier', 'lol.', 'She', 'immediately', 'commented', 'it', 'had', 'a', 'fresh', ',', 'clean', 'vibe', 'and', 'I', 'agree', '...', 'soapy', 'and', 'a', 'hint', 'of', 'powdery', 'but', 'in', 'a', 'good', 'way.', 'I’m', 'obsessed', 'with', 'it', 'and', 'can’t', 'stop', 'smelling', 'my', 'arm.', 'So', 'glad', 'I', 'gave', 'it', 'a', 'try', 'and', 'can', 'not', 'wait', 'to', 'buy', 'a', 'full', 'bottle', '.']\n"
     ]
    }
   ],
   "source": [
    "# Test tokenize\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "print(tokenizer.tokenize(reviews[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [Got, a, sample, of, this, today, ,, and, my, ...\n1    [First, impressions., Test, on, blotter., I, h...\n2    [This, perfume, reminds, me, of, my, best, fri...\n3    [Imagine, tripping, over, your, own, feet, and...\n4    [Gorgeous, Gorgeous, Blend, .., Love, the, sce...\nName: review_tokenized, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_tokenized'] = df['review'].map(lambda review: tokenizer.tokenize(review))\n",
    "df['review_tokenized'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\tools\\anaconda3\\envs\\tensorflow\\lib\\site-packages (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['abc', 'abcd']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_short_word (words):\n",
    "    return [word for word in words if len(word) > 2]\n",
    "\n",
    "def small_letter (words):\n",
    "    return [word.lower() for word in words]\n",
    "\n",
    "def remove_dot (words):\n",
    "    return [word.replace('.', '') for word in words]\n",
    "\n",
    "import re\n",
    "reg = re.compile(r'[^\\x00-\\x7F]+')\n",
    "def remove_non_alphabet (words):\n",
    "    return [word for word in words if not reg.search(word)]\n",
    "\n",
    "def custom_process(words):\n",
    "    words = remove_short_word(words)\n",
    "    words = small_letter(words)\n",
    "    words = remove_dot(words)\n",
    "    words = remove_non_alphabet(words)\n",
    "    words = remove_short_word(words)\n",
    "    return words\n",
    "\n",
    "custom_process(['a', 'ab', 'ab.c', 'aBcD.', 'ㅁㄴㅇㄹasdf'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df['custom_processed'] = df['review_tokenized']\\\n",
    "    .map(lambda words : custom_process(words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   gender                    name                             accords  \\\n0  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n1  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n2  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n3  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n4  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n\n                                              review  \\\n0  Got a sample of this today, and my 9 year old ...   \n1  First impressions. Test on blotter.\\r\\nI have ...   \n2  This perfume reminds me of my best friend. Act...   \n3  Imagine tripping over your own feet and fallin...   \n4  Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....   \n\n                                    review_tokenized  \\\n0  [Got, a, sample, of, this, today, ,, and, my, ...   \n1  [First, impressions., Test, on, blotter., I, h...   \n2  [This, perfume, reminds, me, of, my, best, fri...   \n3  [Imagine, tripping, over, your, own, feet, and...   \n4  [Gorgeous, Gorgeous, Blend, .., Love, the, sce...   \n\n                                    custom_processed  \\\n0  [got, sample, this, today, and, year, old, dau...   \n1  [first, impressions, test, blotter, have, hear...   \n2  [this, perfume, reminds, best, friend, actuall...   \n3  [imagine, tripping, over, your, own, feet, and...   \n4  [gorgeous, gorgeous, blend, love, the, scent, ...   \n\n                             review_lemmatized_basic  \n0  [got, sample, this, today, and, year, old, dau...  \n1  [first, impression, test, blotter, have, heard...  \n2  [this, perfume, reminds, best, friend, actuall...  \n3  [imagine, tripping, over, your, own, foot, and...  \n4  [gorgeous, gorgeous, blend, love, the, scent, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>name</th>\n      <th>accords</th>\n      <th>review</th>\n      <th>review_tokenized</th>\n      <th>custom_processed</th>\n      <th>review_lemmatized_basic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>Got a sample of this today, and my 9 year old ...</td>\n      <td>[Got, a, sample, of, this, today, ,, and, my, ...</td>\n      <td>[got, sample, this, today, and, year, old, dau...</td>\n      <td>[got, sample, this, today, and, year, old, dau...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>First impressions. Test on blotter.\\r\\nI have ...</td>\n      <td>[First, impressions., Test, on, blotter., I, h...</td>\n      <td>[first, impressions, test, blotter, have, hear...</td>\n      <td>[first, impression, test, blotter, have, heard...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>This perfume reminds me of my best friend. Act...</td>\n      <td>[This, perfume, reminds, me, of, my, best, fri...</td>\n      <td>[this, perfume, reminds, best, friend, actuall...</td>\n      <td>[this, perfume, reminds, best, friend, actuall...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>Imagine tripping over your own feet and fallin...</td>\n      <td>[Imagine, tripping, over, your, own, feet, and...</td>\n      <td>[imagine, tripping, over, your, own, feet, and...</td>\n      <td>[imagine, tripping, over, your, own, foot, and...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....</td>\n      <td>[Gorgeous, Gorgeous, Blend, .., Love, the, sce...</td>\n      <td>[gorgeous, gorgeous, blend, love, the, scent, ...</td>\n      <td>[gorgeous, gorgeous, blend, love, the, scent, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "df['review_lemmatized_basic'] = df['custom_processed']\\\n",
    "    .map(lambda words : [wordnet.lemmatize(w) for w in words])\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   gender                    name                             accords  \\\n0  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n1  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n2  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n3  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n4  female  Alien Mugler for women  ['white floral', 'amber', 'woody']   \n\n                                              review  \\\n0  Got a sample of this today, and my 9 year old ...   \n1  First impressions. Test on blotter.\\r\\nI have ...   \n2  This perfume reminds me of my best friend. Act...   \n3  Imagine tripping over your own feet and fallin...   \n4  Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....   \n\n                                    review_tokenized  \\\n0  [Got, a, sample, of, this, today, ,, and, my, ...   \n1  [First, impressions., Test, on, blotter., I, h...   \n2  [This, perfume, reminds, me, of, my, best, fri...   \n3  [Imagine, tripping, over, your, own, feet, and...   \n4  [Gorgeous, Gorgeous, Blend, .., Love, the, sce...   \n\n                                    custom_processed  \\\n0  [got, sample, this, today, and, year, old, dau...   \n1  [first, impressions, test, blotter, have, hear...   \n2  [this, perfume, reminds, best, friend, actuall...   \n3  [imagine, tripping, over, your, own, feet, and...   \n4  [gorgeous, gorgeous, blend, love, the, scent, ...   \n\n                             review_lemmatized_basic  \\\n0  [got, sample, this, today, and, year, old, dau...   \n1  [first, impression, test, blotter, have, heard...   \n2  [this, perfume, reminds, best, friend, actuall...   \n3  [imagine, tripping, over, your, own, foot, and...   \n4  [gorgeous, gorgeous, blend, love, the, scent, ...   \n\n                                   stopwords_removed  \n0  [got, sample, today, year, old, daughter, thou...  \n1  [first, impression, test, blotter, heard, smel...  \n2  [perfume, reminds, best, friend, actually, per...  \n3  [imagine, tripping, foot, falling, face, first...  \n4  [gorgeous, gorgeous, blend, love, scent, fan, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>name</th>\n      <th>accords</th>\n      <th>review</th>\n      <th>review_tokenized</th>\n      <th>custom_processed</th>\n      <th>review_lemmatized_basic</th>\n      <th>stopwords_removed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>Got a sample of this today, and my 9 year old ...</td>\n      <td>[Got, a, sample, of, this, today, ,, and, my, ...</td>\n      <td>[got, sample, this, today, and, year, old, dau...</td>\n      <td>[got, sample, this, today, and, year, old, dau...</td>\n      <td>[got, sample, today, year, old, daughter, thou...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>First impressions. Test on blotter.\\r\\nI have ...</td>\n      <td>[First, impressions., Test, on, blotter., I, h...</td>\n      <td>[first, impressions, test, blotter, have, hear...</td>\n      <td>[first, impression, test, blotter, have, heard...</td>\n      <td>[first, impression, test, blotter, heard, smel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>This perfume reminds me of my best friend. Act...</td>\n      <td>[This, perfume, reminds, me, of, my, best, fri...</td>\n      <td>[this, perfume, reminds, best, friend, actuall...</td>\n      <td>[this, perfume, reminds, best, friend, actuall...</td>\n      <td>[perfume, reminds, best, friend, actually, per...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>Imagine tripping over your own feet and fallin...</td>\n      <td>[Imagine, tripping, over, your, own, feet, and...</td>\n      <td>[imagine, tripping, over, your, own, feet, and...</td>\n      <td>[imagine, tripping, over, your, own, foot, and...</td>\n      <td>[imagine, tripping, foot, falling, face, first...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>female</td>\n      <td>Alien Mugler for women</td>\n      <td>['white floral', 'amber', 'woody']</td>\n      <td>Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....</td>\n      <td>[Gorgeous, Gorgeous, Blend, .., Love, the, sce...</td>\n      <td>[gorgeous, gorgeous, blend, love, the, scent, ...</td>\n      <td>[gorgeous, gorgeous, blend, love, the, scent, ...</td>\n      <td>[gorgeous, gorgeous, blend, love, scent, fan, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk 불용어 처리\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "with open('./perfume_name_words.json', 'r') as f:\n",
    "    stop_words = stop_words | set(json.loads(f.read()))\n",
    "\n",
    "df['stopwords_removed'] = df['review_lemmatized_basic']\\\n",
    "    .map(lambda words : [w for w in words if w not in stop_words])\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [got, sample, this, today, and, year, old, dau...\n",
      "1     [first, impressions, test, blotter, have, hear...\n",
      "2     [this, perfume, reminds, best, friend, actuall...\n",
      "3     [imagine, tripping, over, your, own, feet, and...\n",
      "4     [gorgeous, gorgeous, blend, love, the, scent, ...\n",
      "5     [tested, the, most, recent, formulation, and, ...\n",
      "6     [for, the, last, six, months, 've, been, heari...\n",
      "7     [honestly, for, those, who, have, n't, smelt, ...\n",
      "8     ['ve, recently, discovered, this, perfume, and...\n",
      "9     [did, vote, for, love, but, with, love, meant,...\n",
      "10    [surprised, how, much, enjoy, this, fragrance,...\n",
      "11    [pretty, synthetic, smelling, but, this, the, ...\n",
      "12    [smells, different, than, expected, little, li...\n",
      "13    [lightly, sweet, jasmine, spicy, warm, amber, ...\n",
      "14    [wow, was, adamant, trying, this, one, because...\n",
      "15                    [alien, banger, and, thats, that]\n",
      "16    [this, was, first, full, bottle, purchase, whe...\n",
      "17    [this, hate, men, fragrance, mean, and, says, ...\n",
      "18    [definitely, get, the, hype, for, this, one, l...\n",
      "19    [25y/f, this, one, not, just, jasmine, bomb, c...\n",
      "Name: custom_processed, dtype: object\n",
      "0     [got, sample, this, today, and, year, old, dau...\n",
      "1     [first, impression, test, blotter, have, heard...\n",
      "2     [this, perfume, reminds, best, friend, actuall...\n",
      "3     [imagine, tripping, over, your, own, foot, and...\n",
      "4     [gorgeous, gorgeous, blend, love, the, scent, ...\n",
      "5     [tested, the, most, recent, formulation, and, ...\n",
      "6     [for, the, last, six, month, 've, been, hearin...\n",
      "7     [honestly, for, those, who, have, n't, smelt, ...\n",
      "8     ['ve, recently, discovered, this, perfume, and...\n",
      "9     [did, vote, for, love, but, with, love, meant,...\n",
      "10    [surprised, how, much, enjoy, this, fragrance,...\n",
      "11    [pretty, synthetic, smelling, but, this, the, ...\n",
      "12    [smell, different, than, expected, little, lig...\n",
      "13    [lightly, sweet, jasmine, spicy, warm, amber, ...\n",
      "14    [wow, wa, adamant, trying, this, one, because,...\n",
      "15                    [alien, banger, and, thats, that]\n",
      "16    [this, wa, first, full, bottle, purchase, when...\n",
      "17    [this, hate, men, fragrance, mean, and, say, '...\n",
      "18    [definitely, get, the, hype, for, this, one, l...\n",
      "19    [25y/f, this, one, not, just, jasmine, bomb, c...\n",
      "Name: review_lemmatized_basic, dtype: object\n",
      "0     [got, sample, today, year, old, daughter, thou...\n",
      "1     [first, impression, test, blotter, heard, smel...\n",
      "2     [perfume, reminds, best, friend, actually, per...\n",
      "3     [imagine, tripping, foot, falling, face, first...\n",
      "4     [gorgeous, gorgeous, blend, love, scent, fan, ...\n",
      "5     [tested, recent, formulation, ala, shell, form...\n",
      "6     [last, six, month, i've, hearing, bad, review,...\n",
      "7     [honestly, not, smelt, say, safe, blind, buy, ...\n",
      "8     [i've, recently, discovered, perfume, found, n...\n",
      "9     [vote, love, love, meant, older, version, newe...\n",
      "10    [surprised, much, enjoy, fragrance, much, talk...\n",
      "11    [pretty, synthetic, smelling, scent, found, sy...\n",
      "12    [smell, different, expected, little, lighter, ...\n",
      "13    [lightly, sweet, jasmine, spicy, warm, amber, ...\n",
      "14    [wow, wa, adamant, trying, used, eat, year, ba...\n",
      "15                                      [banger, thats]\n",
      "16    [wa, first, full, bottle, purchase, got, perfu...\n",
      "17    [hate, fragrance, mean, say, stay, away, me, s...\n",
      "18    [definitely, get, hype, love, jasmine, love, a...\n",
      "19    [25y/f, jasmine, bomb, complete, elegant, simp...\n",
      "Name: correction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import correction as c\n",
    "\n",
    "s = c.correction(df)\n",
    "df['correction'] = s\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df.to_csv('./new_proprocessed_02.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'basic_stopwords_removed'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mC:\\tools\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3079\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3080\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'basic_stopwords_removed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-9832dbc8b919>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTokenizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mbasic_stopwords_removed\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'basic_stopwords_removed'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTokenizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\tools\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3022\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3023\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3024\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3025\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\tools\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3080\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3082\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3084\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'basic_stopwords_removed'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "basic_stopwords_removed = df['stopwords_removed']\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(basic_stopwords_removed) # 5169개의 행을 가진 X의 각 행에 토큰화를 수행\n",
    "sequences = tokenizer.texts_to_sequences(basic_stopwords_removed) # 단어\n",
    "\n",
    "print(sequences[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_to_index = tokenizer.word_index\n",
    "print(word_to_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getAppearFrequency(threshold: int):\n",
    "    total_cnt = len(word_to_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "    rare_words =\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    print('')\n",
    "\n",
    "getAppearFrequency(2)\n",
    "getAppearFrequency(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "freq_df = pd.DataFrame(list(tokenizer.word_counts.items()), columns =['word', 'freq'])\n",
    "freq_df = freq_df.sort_values(by=['freq'], axis=0, ascending=False)\n",
    "freq_df['to_remain'] = 1\n",
    "freq_df['to_remain'] = freq_df['to_remain'].map()\n",
    "\n",
    "freq_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "freq_df.to_csv('./word_frequency_save.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 향수 이름 & 브랜드 제거\n",
    "\n",
    "* 우선 브랜드와 향수 list up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./top_90_by_gender.csv')\n",
    "names = list(set(df['name']))\n",
    "\n",
    "names_serial = ''\n",
    "for name in names:\n",
    "    names_serial = names_serial + ' ' + name\n",
    "\n",
    "names_serial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenized_names = tokenizer.tokenize(names_serial)\n",
    "tokenized_names = custom_process(tokenized_names)\n",
    "tokenized_names = list(set(tokenized_names))\n",
    "tokenized_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "serialized = json.dumps(tokenized_names)\n",
    "f = open('./perfume_name_words.json', 'w')\n",
    "f.write(serialized)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1e7c8704",
   "language": "python",
   "display_name": "PyCharm (preprocessing)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}